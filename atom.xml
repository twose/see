<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>SEE</title>
  
  <subtitle>SEE is the sea of cc</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://yoursite.com/"/>
  <updated>2018-01-03T21:49:45.000Z</updated>
  <id>http://yoursite.com/</id>
  
  <author>
    <name>Twosee</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>4种PHP回调函数</title>
    <link href="http://yoursite.com/2018/01/04/PHP-callback/"/>
    <id>http://yoursite.com/2018/01/04/PHP-callback/</id>
    <published>2018-01-03T21:47:33.000Z</published>
    <updated>2018-01-03T21:49:45.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="4种PHP回调函数"><a href="#4种PHP回调函数" class="headerlink" title="4种PHP回调函数"></a>4种PHP回调函数</h1><blockquote><p>以Swoole服务事件回调为例</p></blockquote><h2 id="匿名函数"><a href="#匿名函数" class="headerlink" title="匿名函数"></a>匿名函数</h2><figure class="highlight php"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$server-&gt;on(<span class="string">'Request'</span>, <span class="function"><span class="keyword">function</span> <span class="params">($req, $resp)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">echo</span> <span class="string">"hello world"</span>;</span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure><h2 id="类静态方法"><a href="#类静态方法" class="headerlink" title="类静态方法"></a>类静态方法</h2><figure class="highlight php"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">A</span></span></span><br><span class="line"><span class="class"></span>&#123;</span><br><span class="line">    <span class="keyword">static</span> <span class="function"><span class="keyword">function</span> <span class="title">test</span><span class="params">($req, $resp)</span></span></span><br><span class="line"><span class="function">    </span>&#123;</span><br><span class="line">        <span class="keyword">echo</span> <span class="string">"hello world"</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line">$server-&gt;on(<span class="string">'Request'</span>, <span class="string">'A::Test'</span>);</span><br><span class="line">$server-&gt;on(<span class="string">'Request'</span>, <span class="keyword">array</span>(<span class="string">'A'</span>, <span class="string">'Test'</span>));</span><br></pre></td></tr></table></figure><h2 id="函数"><a href="#函数" class="headerlink" title="函数"></a>函数</h2><figure class="highlight php"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">my_onRequest</span><span class="params">($req, $resp)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">echo</span> <span class="string">"hello world"</span>;</span><br><span class="line">&#125;</span><br><span class="line">$server-&gt;on(<span class="string">'Request'</span>, <span class="string">'my_onRequest'</span>);</span><br></pre></td></tr></table></figure><h2 id="对象方法"><a href="#对象方法" class="headerlink" title="对象方法"></a>对象方法</h2><figure class="highlight php"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">A</span></span></span><br><span class="line"><span class="class"></span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">function</span> <span class="title">test</span><span class="params">($req, $resp)</span></span></span><br><span class="line"><span class="function">    </span>&#123;</span><br><span class="line">        <span class="keyword">echo</span> <span class="string">"hello world"</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">$object = <span class="keyword">new</span> A();</span><br><span class="line">$server-&gt;on(<span class="string">'Request'</span>, <span class="keyword">array</span>($object, <span class="string">'test'</span>));</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;4种PHP回调函数&quot;&gt;&lt;a href=&quot;#4种PHP回调函数&quot; class=&quot;headerlink&quot; title=&quot;4种PHP回调函数&quot;&gt;&lt;/a&gt;4种PHP回调函数&lt;/h1&gt;&lt;blockquote&gt;
&lt;p&gt;以Swoole服务事件回调为例&lt;/p&gt;
&lt;/blockqu
      
    
    </summary>
    
    
      <category term="PHP" scheme="http://yoursite.com/tags/PHP/"/>
    
  </entry>
  
  <entry>
    <title>人人都可以做深度学习应用 加强篇</title>
    <link href="http://yoursite.com/2018/01/04/AI-everyone-plus/"/>
    <id>http://yoursite.com/2018/01/04/AI-everyone-plus/</id>
    <published>2018-01-03T21:40:56.000Z</published>
    <updated>2018-01-03T21:46:35.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="经典入门demo：识别手写数字（MNIST）"><a href="#经典入门demo：识别手写数字（MNIST）" class="headerlink" title="经典入门demo：识别手写数字（MNIST）"></a>经典入门demo：识别手写数字（MNIST）</h2><p>常规的编程入门有“Hello world”程序，而深度学习的入门程序则是MNIST，一个识别28×28像素的图片中的手写数字的程序。</p><p>备注：<a href="http://yann.lecun.com/exdb/mnist/" target="_blank" rel="noopener">MNIST 的数据和官网</a></p><p>深度学习的内容，其背后会涉及比较多的数学原理，作为一个初学者，受限于我个人的数学和技术水平，也许并不足以准确讲述相关的数学原理，因此，本文会更多的关注“应用层面”，不对背后的数学原理进行展开，感谢谅解。</p><a id="more"></a><h3 id="1-加载数据"><a href="#1-加载数据" class="headerlink" title="1. 加载数据"></a>1. 加载数据</h3><p><img src="https://blog-10039692.file.myqcloud.com/1487835237768_1640_1487835232627.png" alt="img"></p><p>程序执行的第一步当然是加载数据，根据我们之前获得的数据集主要包括两部分：60000的训练数据集（mnist.train）和10000的测试数据集（mnist.test）。里面每一行，是一个28×28=784的数组，数组的本质就是将28×28像素的图片，转化成对应的像素点阵。</p><p>例如手写字1的图片转换出来的对应矩阵表示如下：</p><p><img src="https://blog-10039692.file.myqcloud.com/1487835254243_8947_1487835249287.png" alt="img"></p><p>之前我们经常听说，图片方面的深度学习需要大量的计算能力，甚至需要采用昂贵、专业的GPU（Nvidia的GPU），从上述转化的案例我们就已经可以获得一些答案了。一张784像素的图片，对学习模型来说，就有784个特征，而我们实际的相片和图片动辄几十万、百万级别，则对应的基础特征数也是这个数量级，基于这样数量级的数组进行大规模运算，没有强大的计算能力支持，确实寸步难行。当然，这个入门的MNIST的demo还是可以比较快速的跑完。</p><p>Demo中的关键代码（读取并且加载数据到数组对象中，方便后面使用）：</p><p><img src="https://blog-10039692.file.myqcloud.com/1487835274838_4756_1487835269849.png" alt="img"></p><h3 id="2-构建模型"><a href="#2-构建模型" class="headerlink" title="2. 构建模型"></a>2. 构建模型</h3><p>MNIST的每一张图片都表示一个数字，从0到9。而模型最终期望获得的是：给定一张图片，获得代表每个数字的概率。比如说，模型可能推测一张数字9的图片代表数字9的概率是80%但是判断它是8的概率是5%（因为8和9都有上半部分的小圆），然后给予它代表其他数字的概率更小的值。</p><p><img src="https://blog-10039692.file.myqcloud.com/1487835288965_8390_1487835283908.png" alt="img"></p><p>MNIST的入门例子，采用的是softmax回归(softmax regression)，softmax模型可以用来给不同的对象分配概率。<br>为了得到一张给定图片属于某个特定数字类的证据（evidence），我们对图片的784个特征（点阵里的各个像素值）进行加权求和。如果某个特征（像素值）具有很强的证据说明这张图片不属于该类，那么相应的权重值为负数，相反如果某个特征（像素值）拥有有利的证据支持这张图片属于这个类，那么权重值是正数。类似前面提到的房价估算例子，对每一个像素点作出了一个权重分配。</p><p>假设我们获得一张图片，需要计算它是8的概率，转化成数学公式则如下：</p><p><img src="https://blog-10039692.file.myqcloud.com/1487835305590_4981_1487835300408.png" alt="img"></p><p>公式中的i代表需要预测的数字（8），代表预测数字为8的情况下，784个特征的不同权重值，代表8的偏置量（bias），X则是该图片784个特征的值。通过上述计算，我们则可以获得证明该图片是8的证据（evidence）的总和，softmax函数可以把这些证据转换成概率 y。（softmax的数学原理，辛苦各位查询相关资料哈）</p><p>将前面的过程概括成一张图（来自官方）则如下：</p><p><img src="https://blog-10039692.file.myqcloud.com/1487835319864_5485_1487835315023.png" alt="img"></p><p>不同的特征x和对应不同数字的权重进行相乘和求和，则获得在各个数字的分布概率，取概率最大的值，则认为是我们的图片预测结果。</p><p>将上述过程写成一个等式，则如下：</p><p><img src="https://blog-10039692.file.myqcloud.com/1487835336660_2173_1487835331741.png" alt="img"></p><p>该等式在矩阵乘法里可以非常简单地表示，则等价为：</p><p><img src="https://blog-10039692.file.myqcloud.com/1487835350149_4207_1487835345272.png" alt="img"></p><p>不展开里面的具体数值，则可以简化为：</p><p><img src="https://blog-10039692.file.myqcloud.com/1487835363125_5606_1487835358008.png" alt="img"></p><p>如果我们对线性代数中矩阵相关内容有适当学习，其实，就会明白矩阵表达在一些问题上，更易于理解。如果对矩阵内容不太记得了，也没有关系，后面我会附加上线性代数的视频。</p><p>虽然前面讲述了这么多，其实关键代码就四行：</p><p><img src="https://blog-10039692.file.myqcloud.com/1487835377739_8249_1487835372756.png" alt="img"></p><p>上述代码都是类似变量占位符，先设置好模型计算方式，在真实训练流程中，需要批量读取源数据，不断给它们填充数据，模型计算才会真实跑起来。tf.zeros则表示，先给它们统一赋值为0占位。X数据是从数据文件中读取的，而w、b是在训练过程中不断变化和更新的，y则是基于前面的数据进行计算得到。</p><h3 id="3-损失函数和优化设置"><a href="#3-损失函数和优化设置" class="headerlink" title="3. 损失函数和优化设置"></a>3. 损失函数和优化设置</h3><p>为了训练我们的模型，我们首先需要定义一个指标来衡量这个模型是好还是坏。这个指标称为成本（cost）或损失（loss），然后尽量最小化这个指标。简单的说，就是我们需要最小化loss的值，loss的值越小，则我们的模型越逼近标签的真实结果。</p><p>Demo中使用的损失函数是“交叉熵”（cross-entropy），它的公式如下：</p><p><img src="https://blog-10039692.file.myqcloud.com/1487835393807_3301_1487835388666.png" alt="img"></p><p>y 是我们预测的概率分布, y’ 是实际的分布（我们输入的)，交叉熵是用来衡量我们的预测结果的不准确性。TensorFlow拥有一张描述各个计算单元的图，也就是整个模型的计算流程，它可以自动地使用反向传播算法(backpropagation algorithm)，来确定我们的权重等变量是如何影响我们想要最小化的那个loss值的。然后，TensorFlow会用我们设定好的优化算法来不断修改变量以降低loss值。</p><p>其中，demo采用梯度下降算法（gradient descent algorithm）以0.01的学习速率最小化交叉熵。梯度下降算法是一个简单的学习过程，TensorFlow只需将每个变量一点点地往使loss值不断降低的方向更新。</p><p>对应的关键代码如下：</p><p><img src="https://blog-10039692.file.myqcloud.com/1487835412631_4507_1487835407643.png" alt="img"></p><p>备注内容：</p><ul><li><a href="http://colah.github.io/posts/2015-09-Visual-Information/" target="_blank" rel="noopener">交叉熵</a></li><li><a href="http://colah.github.io/posts/2015-08-Backprop/" target="_blank" rel="noopener">反向传播</a></li></ul><p>在代码中会看见one-hot vector的概念和变量名，其实这个是个非常简单的东西，就是设置一个10个元素的数组，其中只有一个是1，其他都是0，以此表示数字的标签结果。<br>例如表示数字3的标签值：<br>[0,0,0,1,0,0,0,0,0,0]</p><h3 id="4-训练运算和模型准确度测试"><a href="#4-训练运算和模型准确度测试" class="headerlink" title="4. 训练运算和模型准确度测试"></a>4. 训练运算和模型准确度测试</h3><p>通过前面的实现，我们已经设置好了整个模型的计算“流程图”，它们都成为TensorFlow框架的一部分。于是，我们就可以启动我们的训练程序，下面的代码的含义是，循环训练我们的模型500次，每次批量取50个训练样本。</p><p><img src="https://blog-10039692.file.myqcloud.com/1487835430926_4789_1487835425964.png" alt="img"></p><p>其训练过程，其实就是TensorFlow框架的启动训练过程，在这个过程中，python批量地将数据交给底层库进行处理。<br>我在官方的demo里追加了两行代码，每隔50次则额外计算一次当前模型的识别准确率。它并非必要的代码，仅仅用于方便观察整个模型的识别准确率逐步变化的过程。</p><p><img src="https://blog-10039692.file.myqcloud.com/1487835491726_6639_1487835486623.png" alt="img"></p><p>当然，里面涉及的accuracy（预测准确率）等变量，需要在前面的地方定义占位：</p><p><img src="https://blog-10039692.file.myqcloud.com/1487835504713_4066_1487835499596.png" alt="img"></p><p>当我们训练完毕，则到了验证我们的模型准确率的时候，和前面相同：</p><p><img src="https://blog-10039692.file.myqcloud.com/1487835519432_6550_1487835514510.png" alt="img"></p><p>我的demo跑出来的结果如下（softmax回归的例子运行速度还是比较快的），当前的准确率是0.9252：</p><p><img src="https://blog-10039692.file.myqcloud.com/1487835591993_6315_1487835586980.png" alt="img"></p><h3 id="5-实时查看参数的数值的方法"><a href="#5-实时查看参数的数值的方法" class="headerlink" title="5. 实时查看参数的数值的方法"></a>5. 实时查看参数的数值的方法</h3><p>刚开始跑官方的demo的时候，我们总想将相关变量的值打印出来看看，是怎样一种格式和状态。从demo的代码中，我们可以看见很多的Tensor变量对象，而实际上这些变量对象都是无法直接输出查看，粗略地理解，有些只是占位符，直接输出的话，会获得类似如下的一个对象：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Tensor(&quot;Equal:0&quot;, shape=(?,), dtype=bool)</span><br></pre></td></tr></table></figure><p>既然它是占位符，那么我们就必须喂一些数据给它，它才能将真实内容展示出来。因此，正确的方法是，在打印时通常需要加上当前的输入数据给它。</p><p>例如，查看y的概率数据：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">print(sess.run(y, feed_dict=&#123;x: batch_xs, y_: batch_ys&#125;))</span><br></pre></td></tr></table></figure><p>部分非占位符的变量还可以这样输出来：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">print(W.eval())</span><br></pre></td></tr></table></figure><p>总的来说，92%的识别准确率是比较令人失望，因此，官方的MNIST其实也有多种模型的不同版本，其中比较适合图片处理的CNN(卷积神经网络)的版本，可以获得99%以上的准确率，当然，它的执行耗时也是比较长的。</p><p>（备注：cnn_mnist.py就是卷积神经网络版本的，后面有附带微云网盘的下载url）</p><p>前馈神经网络（feed-forward neural network）版本的MNIST，可达到97%：</p><p><img src="https://blog-10039692.file.myqcloud.com/1487835615972_112_1487835611123.png" alt="img"></p><p>分享在微云上的数据和源码：<a href="http://url.cn/44aZOpP" target="_blank" rel="noopener">http://url.cn/44aZOpP</a></p><p>（备注：国外网站下载都比较慢，我这份下载相对会快一些，在环境已经搭建完毕的情况下，执行里面的run.py即可）</p><h2 id="五、和业务场景结合的demo：预测用户是否是超级会员身份"><a href="#五、和业务场景结合的demo：预测用户是否是超级会员身份" class="headerlink" title="五、和业务场景结合的demo：预测用户是否是超级会员身份"></a>五、和业务场景结合的demo：预测用户是否是超级会员身份</h2><p>根据前面的内容，我们对上述基于softmax只是三层（输入、处理、输出）的神经网络模型已经比较熟悉，那么，这个模型是否可以应用到我们具体的业务场景中，其中的难度大吗？为了验证这一点，我拿了一些现网的数据来做了这个试验。</p><p><strong>1. 数据准备</strong></p><p><img src="https://blog-10039692.file.myqcloud.com/1487835640707_9298_1487835636110.png" alt="img"></p><p>我将一个现网的电影票活动的用户参与数据，包括点击过哪些按钮、手机平台、IP地址、参与时间等信息抓取了出来。其实这些数据当中是隐含了用户的身份信息的，例如，某些礼包的必须是超级会员身份才能领取，如果这个按钮用户点击领取成功，则可以证明该用户的身份肯定是超级会员身份。当然，我只是将这些不知道相不相关的数据特征直观的整理出来，作为我们的样本数据，然后对应的标签为超级会员身份。</p><p>用于训练的样本数据格式如下：</p><p><img src="https://blog-10039692.file.myqcloud.com/1487835656634_9699_1487835651861.png" alt="img"></p><p>第一列是QQ号码，只做认知标识的，第二列表示是否超级会员身份，作为训练的标签值，后面的就是IP地址，平台标志位以及参与活动的参与记录（0是未成功参与，1表示成功参与）。则获得一个拥有11个特征的数组（经过一些转化和映射，将特别大的数变小）：</p><p>[0.9166666666666666, 0.4392156862745098, 0.984313725490196, 0.7411764705882353, 0.2196078431372549, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0]</p><p>对应的是否是超级数据格式如下，作为监督学习的标签：</p><p>超级会员：[0, 1]<br>非超级会员：[1, 0]</p><p>这里需要专门解释下，在实际应用中需要做数据转换的原因。一方面，将这些数据做一个映射转化，有助于简化数据模型。另一方面，是为了规避NaN的问题，当数值过大，在一些数学指数和除法的浮点数运算中，有可能得到一个无穷大的数值，或者其他溢出的情形，在Python里会变为NaN类型，这个类型会破坏掉后续全部计算结果，导致计算异常。<br>例如下图，就是特征数值过大，在训练过程中，导致中间某些参数累计越来越大，最终导致产生NaN值，后续的计算结果全部被破坏掉：</p><p><img src="https://blog-10039692.file.myqcloud.com/1487835674331_1358_1487835670178.png" alt="img"></p><p>而导致NaN的原因在复杂的数学计算里，会产生无穷大或者无穷小。例如，在我们的这个demo中，产生NaN的原因，主要是因为softmax的计算导致。</p><p><img src="https://blog-10039692.file.myqcloud.com/1487835692586_8707_1487835687457.png" alt="img"></p><p>RuntimeWarning: divide by zero encountered in log</p><p>刚开始做实际的业务应用，就发现经常跑出极奇怪异的结果（遇到NaN问题，我发现程序也能继续走下去），几经排查才发现是NAN值问题，是非常令人沮丧的。当然，经过仔细分析问题，发现也并非没有排查的方式。因为，NaN值是个奇特的类型，可以采用下述编码方式NaN != NaN来检测自己的训练过程中，是否出现的NaN。</p><p>关键程序代码如下：</p><p><img src="https://blog-10039692.file.myqcloud.com/1487835727418_3743_1487835722627.png" alt="img"></p><p>我采用上述方法，非常顺利地找到自己的深度学习程序，在学习到哪一批数据时产生的NaN。因此，很多原始数据我们都会做一个除以某个值，让数值变小的操作。例如官方的MNIST也是这样做的，将256的像素颜色的数值统一除以255，让它们都变成一个小于1的浮点数。</p><p>MNIST在处理原始图片像素特征数据时，也对特征数据进行了变小处理：</p><p><img src="https://blog-10039692.file.myqcloud.com/1487835744753_6167_1487835739920.png" alt="img"></p><p>NaN值问题一度深深地困扰着我（往事不堪回首-__-!!），特别放到这里，避免入门的同学踩坑。</p><p><strong>2. 执行结果</strong></p><p>我准备的训练集（6700）和测试集（1000）数据并不多，不过，超级会员身份的预测准确率最终可以达到87%。虽然，预测准确率是不高，这个可能和我的训练集数据比较少有关系，不过，整个模型也没有花费多少时间，从整理数据、编码、训练到最终跑出结果，只用了2个晚上的时间。</p><p><img src="https://blog-10039692.file.myqcloud.com/1487835762329_1207_1487835757307.png" alt="img"></p><p>下图是两个实际的测试例子，例如，该模型预测第一个QQ用户有82%的概率是非超级会员用户，17.9%的概率为超级会员用户（该预测是准确的）。</p><p><img src="https://blog-10039692.file.myqcloud.com/1487835777596_428_1487835772680.png" alt="img"></p><p>通过上面的这个例子，我们会发觉其实对于某些比较简单的场景下应用，我们是可以比较容易就实现的。</p><h2 id="六、其他模型"><a href="#六、其他模型" class="headerlink" title="六、其他模型"></a>六、其他模型</h2><p><strong>1. CIFAR-10识别图片分类的demo（官方）</strong></p><p>CIFAR-10数据集的分类是机器学习中一个公开的基准测试问题，它任务是对一组32x32RGB的图像进行分类，这些图像涵盖了10个类别：飞机， 汽车， 鸟， 猫， 鹿， 狗， 青蛙， 马， 船和卡车。</p><p>这也是官方的重要demo之一。</p><p><img src="https://blog-10039692.file.myqcloud.com/1487835795488_7154_1487835791177.png" alt="img"></p><p>更详细的介绍内容：</p><ul><li><a href="http://www.cs.toronto.edu/~kriz/cifar.html" target="_blank" rel="noopener">The CIFAR-10 dataset</a></li><li><a href="http://tensorfly.cn/tfdoc/tutorials/deep_cnn.html" target="_blank" rel="noopener">卷积神经网络</a></li></ul><p>该例子执行的过程比较长，需要耐心等待。</p><p>我在机器上的执行过程和结果：</p><p>cifar10_train.py用于训练：</p><p><img src="https://blog-10039692.file.myqcloud.com/1487835815550_5647_1487835810904.png" alt="img"></p><p>cifar10_eval.py用于检验结果：</p><p><img src="https://blog-10039692.file.myqcloud.com/1487835831631_9118_1487835826763.png" alt="img"></p><p>识别率不高是因为该官方模型的识别率本来就不高：</p><p><img src="https://blog-10039692.file.myqcloud.com/1487835846097_1207_1487835841481.png" alt="img"></p><p>另外，官方的例子我首次在1月5日跑的时候，还是有一些小问题的，无法跑起来（最新的官方可能已经修正），建议可以直接使用我放到微云上的版本（代码里面的log和读取文件的路径，需要调整一下）。</p><p>源码下载：<a href="http://url.cn/44mRzBh" target="_blank" rel="noopener">http://url.cn/44mRzBh</a></p><p>微云盘里，不含训练集和测试集的图片数据，但是，程序如果检测到这些图片不存在，会自行下载：</p><p><img src="https://blog-10039692.file.myqcloud.com/1487835865727_7977_1487835861204.png" alt="img"></p><p><strong>2. 是否大于5岁的测试demo</strong></p><p>为了检验softma回归模型是否能够学习到一些我自己设定好的规则，我做了一个小demo来测试。我通过随机数生成的方式构造了一系列的数据，让前面的softmax回归模型去学习，最终看看模型能否通过训练集的学习，最终100%预测这个样本数据是否大于5岁。</p><p>模型和数据本身都比较简单，构造的数据的方式：</p><p>我随机构造一个只有2个特征纬度的样本数据，[year, 1]，其中year随机取值0-10，数字1是放进去作为干扰。</p><p>如果year大于5岁，则标签设置为：[0, 0, 1]；</p><p>否则，标签设置为：[0, 1, 0]。</p><p>生成了6000条假训练集去训练该模型，最终它能做到100%成功预测准确：</p><p><img src="https://blog-10039692.file.myqcloud.com/1487835914467_1332_1487835909518.png" alt="img"></p><p>微云下载（源码下载）：<a href="http://url.cn/44mKFNK" target="_blank" rel="noopener">http://url.cn/44mKFNK</a></p><p><strong>3. 基于RNN的古诗学习</strong></p><p>最开头的AI写古诗，非常令人感到惊艳，那个demo是美国的一个研究者做出来的，能够根据主题生成不能的古诗，而且古诗的质量还比较高。于是，我也尝试在自己的机器上也跑一个能够写古诗的模型，后来我找到的是一个基于RNN的模型。RNN循环神经网络(Recurrent Neural Networks)，是非常常用的深度学习模型之一。我基于一个外部的demo，进行一些调整后跑起一个能够学习古诗和写古诗的比较简单的程序。</p><p>执行写诗（让它写了十首）：</p><ol><li>抑滴留居潋罅斜，二川还羡五侯家。古刘称士身相染，桃李栽林欲称家。回首二毛相喘日，万当仙性尽甘无。如何羽马嘶来泪，不信红峰一寸西。</li><li>废寺松阴月似空，垂杨风起晚光催。乌心不把嫌香径，出定沧洲几好清。兰逐白头邻斧蝶，苍苍归路自清埃。渔樵若欲斜阳羡，桂苑西河碧朔来。</li><li>遥天花落甚巫山，凤珮飞驰不骋庄。翠初才象饮毫势，上月朱炉一重牛。香催戍渚同虚客，石势填楼取蕊红。佳句旧清箱畔意，剪颜相激菊花繁。</li><li>江上萧条第一取，名长经起月还游。数尺温皋云战远，放船乡鬼蘸云多。相逢槛上西风动，莫听风烟认钓鱼。堤费禽雏应昨梦，去朝从此满玄尘。</li><li>避命抛醺背暮时，见川谁哭梦知年。却随筵里腥消极，不遇嘉唐两带春。大岁秘魔窥石税，鹤成应听白云中。朝浮到岸鸱巇恨，不向青青听径长。</li><li>楚田馀绝宇氤氲，细雨洲头万里凉。百叶长看如不尽，水东春夜足残峰。湖头风浪斜暾鼓，北阙别罹初里村。山在四天三顾客，辘轳争养抵丹墀。</li><li>九日重门携手时，吟疑须渴辞金香。钓来犹绕结茶酒，衣上敬亭宁强烧。自明不肯疑恩日，琴馆寒霖急暮霜。划口濡于孤姹末，出谢空卿寄银机。莲龛不足厌丝屦，华骑敷砧出钓矶。</li><li>为到席中逢旧木，容华道路不能休。时闲客后多时石，暗水天边暖人说。风弄霜花嗥明镜，犀成磨逐乍牵肠。何劳相听真行侍，石石班场古政蹄。</li><li>听巾邑外见朱兰，杂时临厢北满香。门外玉坛花府古，香牌风出即升登。陵桥翠黛销仙妙，晓接红楼叠影闻。敢把苦谣金字表，应从科剑独频行。</li><li>昨日荣枯桃李庆，紫骝坚黠自何侵。险知河在皆降月，汉县烟波白发来。仍省封身明月阁，不知吹水洽谁非。更拟惭送风痕去，只怕鲸雏是后仙。</li></ol><p>另外，我抽取其中一些个人认为写得比较好的诗句（以前跑出来的，不在上图中）：</p><p><img src="https://blog-10039692.file.myqcloud.com/1487835938029_9943_1487835933180.png" alt="img"></p><p>该模型比较简单，写诗的水平不如最前面我介绍的美国研究者demo，但是，所采用的基本方法应该是类似的，只是他做的更为复杂。</p><p>另外，这是一个通用模型，可以学习不同的内容（古诗、现代诗、宋词或者英文诗等），就可以生成对应的结果。</p><h2 id="七、深度学习的入门学习体会"><a href="#七、深度学习的入门学习体会" class="headerlink" title="七、深度学习的入门学习体会"></a>七、深度学习的入门学习体会</h2><ol><li>人工智能和深度学习技术并不神秘，更像是一个新型的工具，通过喂数据给它，然后，它能发现这些数据背后的规律，并为我们所用。</li><li>数学基础比较重要，这样有助于理解模型背后的数学原理，不过，从纯应用角度来说，并不一定需要完全掌握数学，也可以提前开始做一些尝试和学习。</li><li>我深深地感到计算资源非常缺乏，每次调整程序的参数或训练数据后，跑完一次训练集经常要很多个小时，部分场景不跑多一些训练集数据，看不出差别，例如写诗的案例。个人感觉，这个是制约AI发展的重要问题，它直接让程序的“调试”效率非常低下。</li><li>中文文档比较少，英文文档也不多，开源社区一直在快速更新，文档的内容过时也比较快。因此，入门学习时遇到的问题会比较多，并且缺乏成型的文档。</li></ol><h2 id="八、小结"><a href="#八、小结" class="headerlink" title="八、小结"></a>八、小结</h2><p>我不知道人工智能的时代是否真的会来临，也不知道它将要走向何方，但是，毫无疑问，它是一种全新的技术思维模式。更好的探索和学习这种新技术，然后在业务应用场景寻求结合点，最终达到帮助我们的业务获得更好的成果，一直以来，就是我们工程师的核心宗旨。另一方面，对发展有重大推动作用的新技术，通常会快速的发展并且走向普及，就如同我们的编程一样，因此，人人都可以做深度学习应用，并非只是一句噱头。</p><p><strong>参考文档：</strong></p><p><a href="http://www.tensorfly.cn/" target="_blank" rel="noopener">TensorFlow中文社区</a><br><a href="https://www.tensorflow.org/" target="_blank" rel="noopener">TensorFlow英文社区</a></p><p><strong>数学相关的内容：</strong></p><p><a href="http://url.cn/44r6LAQ" target="_blank" rel="noopener">高中和大学数学部分内容</a><br><a href="http://open.163.com/special/opencourse/daishu.html" target="_blank" rel="noopener">线性代数视频</a></p><blockquote><p>转载自小时光茶社</p></blockquote>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;经典入门demo：识别手写数字（MNIST）&quot;&gt;&lt;a href=&quot;#经典入门demo：识别手写数字（MNIST）&quot; class=&quot;headerlink&quot; title=&quot;经典入门demo：识别手写数字（MNIST）&quot;&gt;&lt;/a&gt;经典入门demo：识别手写数字（MNIST）&lt;/h2&gt;&lt;p&gt;常规的编程入门有“Hello world”程序，而深度学习的入门程序则是MNIST，一个识别28×28像素的图片中的手写数字的程序。&lt;/p&gt;
&lt;p&gt;备注：&lt;a href=&quot;http://yann.lecun.com/exdb/mnist/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;MNIST 的数据和官网&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;深度学习的内容，其背后会涉及比较多的数学原理，作为一个初学者，受限于我个人的数学和技术水平，也许并不足以准确讲述相关的数学原理，因此，本文会更多的关注“应用层面”，不对背后的数学原理进行展开，感谢谅解。&lt;/p&gt;
    
    </summary>
    
    
      <category term="AI" scheme="http://yoursite.com/tags/AI/"/>
    
  </entry>
  
  <entry>
    <title>人人都可以做深度学习应用 入门篇</title>
    <link href="http://yoursite.com/2018/01/04/AI-everyone/"/>
    <id>http://yoursite.com/2018/01/04/AI-everyone/</id>
    <published>2018-01-03T21:38:41.000Z</published>
    <updated>2018-01-03T21:40:36.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="一、人工智能和新科技革命"><a href="#一、人工智能和新科技革命" class="headerlink" title="一、人工智能和新科技革命"></a>一、人工智能和新科技革命</h2><p>2017年围棋界发生了一件比较重要事，Master（Alphago）以60连胜横扫天下，击败各路世界冠军，人工智能以气势如虹的姿态出现在我们人类的面前。围棋曾经一度被称为“人类智慧的堡垒”，如今，这座堡垒也随之成为过去。从2016年三月份AlphaGo击败李世石开始，AI全面进入我们大众的视野，对于它的讨论变得更为火热起来，整个业界普遍认为，它很可能带来下一次科技革命，并且，在未来可预见的10多年里，深刻地改变我们的生活。</p><a id="more"></a><p>其实，AI除了可以做我们熟知的人脸、语音等识别之外，它可以做蛮多有趣的事情。</p><p>例如，让AI学习大量古诗之后写古诗，并且可以写出质量非常不错的古诗。</p><p><img src="https://blog-10039692.file.myqcloud.com/1487834861894_8010_1487834857060.png" alt="img"></p><p>又或者，将两部设计造型不同的汽车进行融合，形成全新一种设计风格的新汽车造型。</p><p><img src="https://blog-10039692.file.myqcloud.com/1487834872575_2690_1487834867777.png" alt="img"></p><p>还有，之前大家在朋友圈里可能看过的，将相片转换成对应的艺术风格的画作。</p><p><img src="https://blog-10039692.file.myqcloud.com/1487834879897_8519_1487834875505.png" alt="img"></p><p>当前，人工智能已经在图像、语音等多个领域的技术上，取得了全面的突破。与此同时，另外一个问题随之而来，如果这一轮的AI浪潮真的将会掀起新的科技革命，那么在可预见的未来，我们整个互联网都将发生翻天覆地的变化，深刻影响我们的生活。那么作为普通业务开发工程师的我，又应该以何种态度和方式应对这场时代洪流的冲击呢？</p><p>在回答这个问题之前，我们先一起看看上一轮由计算机信息技术引领的科技革命中，过去30多年中国程序员的角色变化：</p><p><img src="https://blog-10039692.file.myqcloud.com/1487834896098_7431_1487834891171.png" alt="img"></p><p>通过上图可以简总结：编程技术在不断地发展并且走向普及，从最开始掌握在科学家和专家学者手中的技能，逐渐发展为一门大众技能。换而言之，我们公司内很多资深的工程师，如果带着今天对编程和计算机的理解和理念回到1980年，那么他无疑就是那个时代的计算机专家。</p><p>如果这一轮AI浪潮真的会带来新的一轮科技革命，那么我们相信，它也会遵循类似的发展轨迹，逐步发展和走向普及。如果基于这个理解，或许，我们可以通过积极学习，争取成为第一代AI工程师。</p><h2 id="二、深度学习技术"><a href="#二、深度学习技术" class="headerlink" title="二、深度学习技术"></a>二、深度学习技术</h2><p>这一轮AI的技术突破，主要源于深度学习技术，而关于AI和深度学习的发展历史我们这里不重复讲述，可自行查阅。我用了一个多月的业务时间，去了解和学习了深度学习技术，在这里，我尝试以一名业务开发工程师的视角，以尽量容易让大家理解的方式一起探讨下深度学习的原理，尽管，受限于我个人的技术水平和掌握程度，未必完全准确。</p><h3 id="1-人的智能和神经元"><a href="#1-人的智能和神经元" class="headerlink" title="1. 人的智能和神经元"></a>1. 人的智能和神经元</h3><p>人类智能最重要的部分是大脑，大脑虽然复杂，它的组成单元却是相对简单的，大脑皮层以及整个神经系统，是由神经元细胞组成的。而一个神经元细胞，由树突和轴突组成，它们分别代表输入和输出。连在细胞膜上的分叉结构叫树突，是输入，那根长长的“尾巴”叫轴突，是输出。神经元输出的有电信号和化学信号，最主要的是沿着轴突细胞膜表面传播的一个电脉冲。忽略掉各种细节，神经元，就是一个积累了足够的输入，就产生一次输出（兴奋）的相对简单的装置。</p><p><img src="https://blog-10039692.file.myqcloud.com/1487834910348_1293_1487834905492.png" alt="img"></p><p>树突和轴突都有大量的分支，轴突的末端通常连接到其他细胞的树突上，连接点上是一个叫“突触”的结构。一个神经元的输出通过突触传递给成千上万个下游的神经元，神经元可以调整突触的结合强度，并且，有的突触是促进下游细胞的兴奋，有的是则是抑制。一个神经元有成千上万个上游神经元，积累它们的输入，产生输出。</p><p><img src="https://blog-10039692.file.myqcloud.com/1487834927553_2814_1487834922786.png" alt="img"></p><p>人脑有1000亿个神经元，1000万亿个突触，它们组成人脑中庞大的神经网络，最终产生的结果即是人的智能。</p><h3 id="2-人工神经元和神经网络"><a href="#2-人工神经元和神经网络" class="headerlink" title="2. 人工神经元和神经网络"></a>2. 人工神经元和神经网络</h3><p>一个神经元的结构相对来说是比较简单的，于是，科学家们就思考，我们的AI是否可以从中获得借鉴？神经元接受激励，输出一个响应的方式，同计算机中的输入输出非常类似，看起来简直就是量身定做的，刚好可以用一个函数来模拟。</p><p><img src="https://blog-10039692.file.myqcloud.com/1487834991434_745_1487834986421.png" alt="img"></p><p>通过借鉴和参考神经元的机制，科学家们模拟出了人工神经元和人工神经网络。当然，通过上述这个抽象的描述和图，比较难让大家理解它的机制和原理。我们以“房屋价格测算”作为例子，一起来看看：</p><p>一套房子的价格，会受到很多因素的影响，例如地段、朝向、房龄、面积、银行利率等等，这些因素如果细分，可能会有几十个。一般在深度学习模型里，这些影响结果的因素我们称之为特征。我们先假设一种极端的场景，例如影响价格的特征只有一种，就是房子面积。于是我们收集一批相关的数据，例如，50平米50万、93平米95万等一系列样本数据，如果将这些样本数据放到而为坐标里看，则如下图：</p><p><img src="https://blog-10039692.file.myqcloud.com/1487835009033_4366_1487835004171.png" alt="img"></p><p>然后，正如我们前面所说的，我们尝试用一个“函数”去拟合这个输入（面积x）和输出（价格y），简而言之，我们就是要通过一条直线或者曲线将这些点“拟合”起来。</p><p>假设情况也比较极端，这些点刚好可以用一条“直线”拟合（真实情况通常不会是直线），如下图：</p><p><img src="https://blog-10039692.file.myqcloud.com/1487835032138_9123_1487835027439.png" alt="img"></p><p>那么我们的函数是一个一次元方程f(x) = ax +b，当然，如果是曲线的话，我们得到的将是多次元方程。我们获得这个f(x) = ax +b的函数之后，接下来就可以做房价“预测”，例如，我们可以计算一个我们从未看见的面积案例81.5平方米，它究竟是多少钱？</p><p>这个新的样本案例，可以通过直线找到对应的点（黄色的点），如图下：</p><p><img src="https://blog-10039692.file.myqcloud.com/1487835046807_828_1487835042188.png" alt="img"></p><p>粗略的理解，上面就是AI的概括性的运作方式。这一切似乎显得过于简单了？当然不会，因为，我们前面提到，影响房价其实远不止一个特征，而是有几十个，这样问题就比较复杂了，接下来，这里则要继续介绍深度学习模型的训练方式。这部分内容相对复杂一点，我尽量以业务工程师的视角来做一个粗略而简单的阐述。</p><h3 id="3-深度学习模型的训练方式"><a href="#3-深度学习模型的训练方式" class="headerlink" title="3. 深度学习模型的训练方式"></a>3. 深度学习模型的训练方式</h3><p>当有好几十个特征共同影响价格的时候，自然就会涉及权重分配的问题，例如有一些对房价是主要正权重的，例如地段、面积等，也有一些是负权重的，例如房龄等。</p><p>（1）初始化权重计算</p><p>那么，第一个步其实是给这些特征加一个权重值，但是，最开始我们根本不知道这些权重值是多少？怎么办呢？不管那么多了，先给它们随机赋值吧。随机赋值，最终计算出来的估算房价肯定是不准确的，例如，它可能将价值100万的房子，计算成了10万。</p><p>（2）损失函数</p><p>因为现在模型的估值和实际估值差距比较大，于是，我们需要引入一个评估“不准确”程度的衡量角色，也就是损失（loss）函数，它是衡量模型估算值和真实值差距的标准，损失函数越小，则模型的估算值和真实值的察觉越小，而我们的根本目的，就是降低这个损失函数。让刚刚的房子特征的模型估算值，逼近100万的估算结果。</p><p>（3）模型调整</p><p>通过梯度下降和反向传播，计算出朝着降低损失函数的方向调整权重参数。举一个不恰当的比喻，我们给面积增加一些权重，然后给房子朝向减少一些权重（实际计算方式，并非针对单个个例特征的调整），然后损失函数就变小了。</p><p>（4）循环迭代</p><p>调整了模型的权重之后，就可以又重新取一批新的样本数据，重复前面的步骤，经过几十万次甚至更多的训练次数，最终估算模型的估算值逼近了真实值结果，这个模型的则是我们要的“函数”。</p><p><img src="https://blog-10039692.file.myqcloud.com/1487835065513_3162_1487835060855.png" alt="img"></p><p>为了让大家更容易理解和直观，采用的例子比较粗略，并且讲述深度学习模型的训练过程，中间省略了比较多的细节。讲完了原理，那么我们就开始讲讲如何学习和搭建demo。</p><h3 id="三、深度学习环境搭建"><a href="#三、深度学习环境搭建" class="headerlink" title="三、深度学习环境搭建"></a>三、深度学习环境搭建</h3><p>在2个月前，人工智能对我来说，只是一个高大上的概念。但是，经过一个多月的业余时间的认真学习，我发现还是能够学到一些东西，并且跑一些demo和应用出来的。</p><p><strong>1. 学习的提前准备</strong></p><p>（1）部分数学内容的复习，高中数学、概率、线性代数等部分内容。（累计花费了10个小时，挑了关键的点看了下，其实还是不太够，只能让自己看公式的时候，相对没有那么懵）</p><p>（2）Python基础语法学习。（花费了3个小时左右，我以前从未写过Python，因为后面Google的TensorFlow框架的使用是基于Python的）</p><p>（3）Google的TensorFlow深度学习开源框架。（花费了10多个小时去看）</p><p>数学基础好或者前期先不关注原理的同学，数学部分不看也可以开始做，全凭个人选择。</p><p><strong>2. Google的TensorFlow开源深度学习框架</strong></p><p>深度学习框架，我们可以粗略的理解为是一个“数学函数”集合和AI训练学习的执行框架。通过它，我们能够更好的将AI的模型运行和维护起来。</p><p>深度学习的框架有各种各样的版本（Caffe、Torch、Theano等等），我只接触了Google的TensorFlow，因此，后面的内容都是基于TensorFlow展开的，它的详细介绍这里不展开讲述，建议直接进入官网查看。非常令人庆幸的是TensorFlow比较早就有中文社区了，尽管里面的内容有一点老，搭建环境方面有一些坑，但是已经属于为数不多的中文文档了，大家且看且珍惜。</p><p><a href="http://www.tensorfly.cn/" target="_blank" rel="noopener">TensorFlow 的中文社区</a></p><p><a href="https://www.tensorflow.org/" target="_blank" rel="noopener">TensorFlow 的英文社区</a></p><p><strong>3. TensorFlow环境搭建</strong></p><p>环境搭建本身并不复杂，主要解决相关的依赖。但是，基础库的依赖可以带来很多问题，因此，建议尽量一步到位，会简单很多。</p><p><strong>（1）操作系统</strong></p><p>我搭建环境使用的机器是腾讯云上的机器，软件环境如下：</p><p>操作系统：CentOS 7.2 64位（GCC 4.8.5）</p><p>因为这个框架依赖于python2.7和glibc 2.17。比较旧的版本的CentOS一般都是python2.6以及版本比较低的glibc，会产生比较的多基础库依赖问题。而且，glibc作为Linux的底层库，牵一发动全身，直接对它升级是比较复杂，很可能会带来更多的环境异常问题。</p><p><strong>（2）软件环境</strong></p><p>我目前安装的Python版本是python-2.7.5，建议可以采用yum install python的方式安装相关的原来软件。然后，再安装 python内的组件包管理器pip，安装好pip之后，接下来的其他软件的安装就相对比较简单了。</p><p>例如安装TensorFlow，可通过如下一句命令完成（它会自动帮忙解决一些库依赖问题）：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install -U tensorflow</span><br></pre></td></tr></table></figure><p>这里需要特别注意的是，不要按照TensorFlow的中文社区的指引去安装，因为它会安装一个非常老的版本（0.5.0），用这个版本跑很多demo都会遇到问题的。而实际上，目前通过上述提供的命令安装，是tensorflow (1.0.0)的版本了。</p><p><img src="https://blog-10039692.file.myqcloud.com/1487835098838_424_1487835093742.png" alt="img"></p><p>Python（2.7.5）下的其他需要安装的关键组件：</p><ul><li>tensorflow (0.12.1)，深度学习的核心框架</li><li>image (1.5.5)，图像处理相关，部分例子会用到</li><li>PIL (1.1.7)，图像处理相关，部分例子会用到</li></ul><p>除此之后，当然还有另外的一些依赖组件，通过pip list命令可以查看我们安装的python组件：</p><ul><li>appdirs (1.4.0)</li><li>backports.ssl-match-hostname (3.4.0.2)</li><li>chardet (2.2.1)</li><li>configobj (4.7.2)</li><li>decorator (3.4.0)</li><li>Django (1.10.4)</li><li>funcsigs (1.0.2)</li><li>image (1.5.5)</li><li>iniparse (0.4)</li><li>kitchen (1.1.1)</li><li>langtable (0.0.31)</li><li>mock (2.0.0)</li><li>numpy (1.12.0)</li><li>packaging (16.8)</li><li>pbr (1.10.0)</li><li>perf (0.1)</li><li>PIL (1.1.7)</li><li>Pillow (3.4.2)</li><li>pip (9.0.1)</li><li>protobuf (3.2.0)</li><li>pycurl (7.19.0)</li><li>pygobject (3.14.0)</li><li>pygpgme (0.3)</li><li>pyliblzma (0.5.3)</li><li>pyparsing (2.1.10)</li><li>python-augeas (0.5.0)</li><li>python-dmidecode (3.10.13)</li><li>pyudev (0.15)</li><li>pyxattr (0.5.1)</li><li>setuptools (34.2.0)</li><li>six (1.10.0)</li><li>slip (0.4.0)</li><li>slip.dbus (0.4.0)</li><li>tensorflow (1.0.0)</li><li>urlgrabber (3.10)</li><li>wheel (0.29.0)</li><li>yum-langpacks (0.4.2)</li><li>yum-metadata-parser (1.1.4)</li></ul><p>按照上述提供的来搭建系统，可以规避不少的环境问题。</p><p>搭建环境的过程中，我遇到不少问题。例如：在跑官方的例子时的某个报错，AttributeError: ‘module’ object has no attribute ‘gfile’，就是因为安装的TensorFlow的版本比较老，缺少gfile模块导致的。而且，还有各种各样的。（不要问我是怎么知道的，说多了都是泪啊~）</p><p>更详细的安装说明：<a href="https://www.tensorflow.org/install/install_linux" target="_blank" rel="noopener">Installing TensorFlow on Ubuntu</a></p><p><strong>（3）TensorFlow环境测试运行</strong></p><p>测试是否安装成功，可以采用官方的提供的一个短小的例子，demo生成了一些三维数据, 然后用一个平面拟合它们（官网的例子采用的初始化变量的函数是initialize_all_variables，该函数在新版本里已经被废弃了）：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line">#!/usr/bin/python</span><br><span class="line">#coding=utf-8</span><br><span class="line"></span><br><span class="line">import tensorflow as tf</span><br><span class="line">import numpy as np</span><br><span class="line"></span><br><span class="line"># 使用 NumPy 生成假数据(phony data), 总共 100 个点.</span><br><span class="line">x_data = np.float32(np.random.rand(2, 100)) # 随机输入</span><br><span class="line">y_data = np.dot([0.100, 0.200], x_data) + 0.300</span><br><span class="line"></span><br><span class="line"># 构造一个线性模型</span><br><span class="line"># </span><br><span class="line">b = tf.Variable(tf.zeros([1]))</span><br><span class="line">W = tf.Variable(tf.random_uniform([1, 2], -1.0, 1.0))</span><br><span class="line">y = tf.matmul(W, x_data) + b</span><br><span class="line"></span><br><span class="line"># 最小化方差</span><br><span class="line">loss = tf.reduce_mean(tf.square(y - y_data))</span><br><span class="line">optimizer = tf.train.GradientDescentOptimizer(0.5)</span><br><span class="line">train = optimizer.minimize(loss)</span><br><span class="line"></span><br><span class="line"># 初始化变量,旧函数（initialize_all_variables）已经被废弃，替换为新函数</span><br><span class="line">init = tf.global_variables_initializer()</span><br><span class="line"></span><br><span class="line"># 启动图 (graph)</span><br><span class="line">sess = tf.Session()</span><br><span class="line">sess.run(init)</span><br><span class="line"></span><br><span class="line"># 拟合平面</span><br><span class="line">for step in xrange(0, 201):</span><br><span class="line">    sess.run(train)</span><br><span class="line">    if step % 20 == 0:</span><br><span class="line">        print step, sess.run(W), sess.run(b)</span><br><span class="line"></span><br><span class="line"># 得到最佳拟合结果 W: [[0.100  0.200]], b: [0.300]</span><br></pre></td></tr></table></figure><p>运行的结果类似如下：</p><p><img src="https://blog-10039692.file.myqcloud.com/1487835204779_9711_1487835200218.png" alt="img"></p><p>经过200次的训练，模型的参数逐渐逼近最佳拟合的结果（W: [[0.100 0.200]], b: [0.300]），另外，我们也可以从代码的“风格”中，了解到框架样本训练的基本运行方式。虽然，官方的教程后续会涉及越来越多更复杂的例子，但从整体上看，也是类似的模式。</p><p><img src="https://blog-10039692.file.myqcloud.com/1487835221851_3503_1487835216851.png" alt="img"></p><p><strong>步骤划分</strong></p><ul><li>准备数据：获得有标签的样本数据（带标签的训练数据称为有监督学习）；</li><li>设置模型：先构建好需要使用的训练模型，可供选择的机器学习方法其实也挺多的，换而言之就是一堆数学函数的集合；<br>损失函数和优化方式：衡量模型计算结果和真实标签值的差距；</li><li>真实训练运算：训练之前构造好的模型，让程序通过循环训练和学习，获得最终我们需要的结果“参数”；</li><li>验证结果：采用之前模型没有训练过的测试集数据，去验证模型的准确率。</li></ul><p>其中，TensorFlow为了基于python实现高效的数学计算，通常会使用到一些基础的函数库，例如Numpy（采用外部底层语言实现），但是，从外部计算切回到python也是存在开销的，尤其是在几万几十万次的训练过程。因此，Tensorflow不单独地运行单一的函数计算，而是先用图描述一系列可交互的计算操作流程，然后全部一次性提交到外部运行（在其他机器学习的库里，也是类似的实现）。</p><p>所以，上述流程图中，蓝色部分都只是设置了“计算操作流程”，而绿色部分开始才是真正的提交数据给到底层库进行实际运算，而且，每次训练一般是批量执行一批数据的。</p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;一、人工智能和新科技革命&quot;&gt;&lt;a href=&quot;#一、人工智能和新科技革命&quot; class=&quot;headerlink&quot; title=&quot;一、人工智能和新科技革命&quot;&gt;&lt;/a&gt;一、人工智能和新科技革命&lt;/h2&gt;&lt;p&gt;2017年围棋界发生了一件比较重要事，Master（Alphago）以60连胜横扫天下，击败各路世界冠军，人工智能以气势如虹的姿态出现在我们人类的面前。围棋曾经一度被称为“人类智慧的堡垒”，如今，这座堡垒也随之成为过去。从2016年三月份AlphaGo击败李世石开始，AI全面进入我们大众的视野，对于它的讨论变得更为火热起来，整个业界普遍认为，它很可能带来下一次科技革命，并且，在未来可预见的10多年里，深刻地改变我们的生活。&lt;/p&gt;
    
    </summary>
    
    
      <category term="AI" scheme="http://yoursite.com/tags/AI/"/>
    
  </entry>
  
  <entry>
    <title>PHP Next JIT</title>
    <link href="http://yoursite.com/2018/01/04/PHP-Next-JIT/"/>
    <id>http://yoursite.com/2018/01/04/PHP-Next-JIT/</id>
    <published>2018-01-03T21:28:57.000Z</published>
    <updated>2018-01-03T21:32:34.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="鸟哥：PHP-Next-JIT"><a href="#鸟哥：PHP-Next-JIT" class="headerlink" title="鸟哥：PHP Next: JIT"></a>鸟哥：PHP Next: JIT</h1><p>12月23日，由开源中国联合中国电子技术标准化研究院主办的2017源创会年终盛典在北京万豪酒店顺利举行。作为年末最受期待的开源技术分享盛会，国内顶尖技术大拿、知名技术团队、优秀开源项目作者，及近1000名技术爱好者共聚一堂，探讨最前沿、最流行的技术话题和方向，推动国内开源创新体系发展，共建国内开源生态标准。PHP7 已发布近两年, 大幅的性能提升使得 PHP 的应用场景更加广泛，刚刚发布的 PHP7.2 相比 PHP7.1 又有了近 10% 的提升。在本次大会上，链家集团技术副总裁、PHP 开发组核心成员鸟哥发表了以 “ PHP Next: JIT ”为主题的演讲，分享了 PHP 的下一个性能提升的主要举措：JIT 的进展, 以及下一个大版本的 PHP 可能的特性。他表示，JIT 相比 PHP7.2 ，在一些场景可以达到三倍，但由于 JIT 的核心前提是类型推断，得到的信息越多效果越好，因此也容易受到限制。 JIT 发布后，随着更优秀的代码出现，性能提升会更明显。</p><h2 id="惠新宸"><a href="#惠新宸" class="headerlink" title="惠新宸"></a>惠新宸</h2><p>惠新宸 ，国内最有影响力的PHP技术专家， PHP开发组核心成员 , PECL开发者 , Zend公司外聘顾问, 曾供职于雅虎，百度，新浪。现任链家集团技术副总裁兼总架构师。PHP 7 的核心开发者，PHP5.4，5.5的主要开发者。也是Yaf (Yet another framework)，Yar(Yet another RPC framework) 以及Yac(Yet another Cache)、Taint等多个开源项目的作者，同时也是APC，Opcache ，Msgpack等项目的维护者。</p><h2 id="演讲实录"><a href="#演讲实录" class="headerlink" title="演讲实录"></a>演讲实录</h2><p><strong>PHP Next: JIT</strong></p><p><img src="http://blog.p2hp.com/wp-content/uploads/2017/12/beepress-beepress-weixin-zhihu-jianshu-plugin-2-4-2-4899-1514626739-1.jpeg" alt="鸟哥：PHP Next: JIT"></p><p><img src="http://blog.p2hp.com/wp-content/uploads/2017/12/beepress-beepress-weixin-zhihu-jianshu-plugin-2-4-2-4899-1514626740.jpeg" alt="鸟哥：PHP Next: JIT"></p><a id="more"></a><p><img src="http://blog.p2hp.com/wp-content/uploads/2017/12/beepress-beepress-weixin-zhihu-jianshu-plugin-2-4-2-4899-1514626740-1.jpeg" alt="鸟哥：PHP Next: JIT"></p><p><img src="http://blog.p2hp.com/wp-content/uploads/2017/12/beepress-beepress-weixin-zhihu-jianshu-plugin-2-4-2-4899-1514626741.jpeg" alt="鸟哥：PHP Next: JIT"></p><p><img src="http://blog.p2hp.com/wp-content/uploads/2017/12/beepress-beepress-weixin-zhihu-jianshu-plugin-2-4-2-4899-1514626742.jpeg" alt="鸟哥：PHP Next: JIT"></p><p><img src="http://blog.p2hp.com/wp-content/uploads/2017/12/beepress-beepress-weixin-zhihu-jianshu-plugin-2-4-2-4899-1514626742-1.jpeg" alt="鸟哥：PHP Next: JIT"></p><p><img src="http://blog.p2hp.com/wp-content/uploads/2017/12/beepress-beepress-weixin-zhihu-jianshu-plugin-2-4-2-4899-1514626743.jpeg" alt="鸟哥：PHP Next: JIT"></p><p><img src="http://blog.p2hp.com/wp-content/uploads/2017/12/beepress-beepress-weixin-zhihu-jianshu-plugin-2-4-2-4899-1514626743-1.jpeg" alt="鸟哥：PHP Next: JIT"></p><p><img src="http://blog.p2hp.com/wp-content/uploads/2017/12/beepress-beepress-weixin-zhihu-jianshu-plugin-2-4-2-4899-1514626744.jpeg" alt="鸟哥：PHP Next: JIT"></p><p><img src="http://blog.p2hp.com/wp-content/uploads/2017/12/beepress-beepress-weixin-zhihu-jianshu-plugin-2-4-2-4899-1514626744-1.jpeg" alt="鸟哥：PHP Next: JIT"></p><p><img src="http://blog.p2hp.com/wp-content/uploads/2017/12/beepress-beepress-weixin-zhihu-jianshu-plugin-2-4-2-4899-1514626745.jpeg" alt="鸟哥：PHP Next: JIT"></p><p><img src="http://blog.p2hp.com/wp-content/uploads/2017/12/beepress-beepress-weixin-zhihu-jianshu-plugin-2-4-2-4899-1514626745-1.jpeg" alt="鸟哥：PHP Next: JIT"></p><p><img src="http://blog.p2hp.com/wp-content/uploads/2017/12/beepress-beepress-weixin-zhihu-jianshu-plugin-2-4-2-4899-1514626746.jpeg" alt="鸟哥：PHP Next: JIT"></p><p><img src="http://blog.p2hp.com/wp-content/uploads/2017/12/beepress-beepress-weixin-zhihu-jianshu-plugin-2-4-2-4899-1514626746-1.jpeg" alt="鸟哥：PHP Next: JIT"></p><p><img src="http://blog.p2hp.com/wp-content/uploads/2017/12/beepress-beepress-weixin-zhihu-jianshu-plugin-2-4-2-4899-1514626747.jpeg" alt="鸟哥：PHP Next: JIT"></p><p><img src="http://blog.p2hp.com/wp-content/uploads/2017/12/beepress-beepress-weixin-zhihu-jianshu-plugin-2-4-2-4899-1514626747-1.jpeg" alt="鸟哥：PHP Next: JIT"></p><p><img src="http://blog.p2hp.com/wp-content/uploads/2017/12/beepress-beepress-weixin-zhihu-jianshu-plugin-2-4-2-4899-1514626747-2.jpeg" alt="鸟哥：PHP Next: JIT"></p><p><img src="http://blog.p2hp.com/wp-content/uploads/2017/12/beepress-beepress-weixin-zhihu-jianshu-plugin-2-4-2-4899-1514626748.jpeg" alt="鸟哥：PHP Next: JIT"></p><p><img src="http://blog.p2hp.com/wp-content/uploads/2017/12/beepress-beepress-weixin-zhihu-jianshu-plugin-2-4-2-4899-1514626748-1.jpeg" alt="鸟哥：PHP Next: JIT"></p><p><img src="http://blog.p2hp.com/wp-content/uploads/2017/12/beepress-beepress-weixin-zhihu-jianshu-plugin-2-4-2-4899-1514626749.jpeg" alt="鸟哥：PHP Next: JIT"></p><p><img src="http://blog.p2hp.com/wp-content/uploads/2017/12/beepress-beepress-weixin-zhihu-jianshu-plugin-2-4-2-4899-1514626749-1.jpeg" alt="鸟哥：PHP Next: JIT"></p><p><img src="http://blog.p2hp.com/wp-content/uploads/2017/12/beepress-beepress-weixin-zhihu-jianshu-plugin-2-4-2-4899-1514626750.jpeg" alt="鸟哥：PHP Next: JIT"></p><p><img src="http://blog.p2hp.com/wp-content/uploads/2017/12/beepress-beepress-weixin-zhihu-jianshu-plugin-2-4-2-4899-1514626750-1.jpeg" alt="鸟哥：PHP Next: JIT"></p><p><img src="http://blog.p2hp.com/wp-content/uploads/2017/12/beepress-beepress-weixin-zhihu-jianshu-plugin-2-4-2-4899-1514626750-2.jpeg" alt="鸟哥：PHP Next: JIT"></p><p><img src="http://blog.p2hp.com/wp-content/uploads/2017/12/beepress-beepress-weixin-zhihu-jianshu-plugin-2-4-2-4899-1514626751.jpeg" alt="鸟哥：PHP Next: JIT"></p>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;鸟哥：PHP-Next-JIT&quot;&gt;&lt;a href=&quot;#鸟哥：PHP-Next-JIT&quot; class=&quot;headerlink&quot; title=&quot;鸟哥：PHP Next: JIT&quot;&gt;&lt;/a&gt;鸟哥：PHP Next: JIT&lt;/h1&gt;&lt;p&gt;12月23日，由开源中国联合中国电子技术标准化研究院主办的2017源创会年终盛典在北京万豪酒店顺利举行。作为年末最受期待的开源技术分享盛会，国内顶尖技术大拿、知名技术团队、优秀开源项目作者，及近1000名技术爱好者共聚一堂，探讨最前沿、最流行的技术话题和方向，推动国内开源创新体系发展，共建国内开源生态标准。PHP7 已发布近两年, 大幅的性能提升使得 PHP 的应用场景更加广泛，刚刚发布的 PHP7.2 相比 PHP7.1 又有了近 10% 的提升。在本次大会上，链家集团技术副总裁、PHP 开发组核心成员鸟哥发表了以 “ PHP Next: JIT ”为主题的演讲，分享了 PHP 的下一个性能提升的主要举措：JIT 的进展, 以及下一个大版本的 PHP 可能的特性。他表示，JIT 相比 PHP7.2 ，在一些场景可以达到三倍，但由于 JIT 的核心前提是类型推断，得到的信息越多效果越好，因此也容易受到限制。 JIT 发布后，随着更优秀的代码出现，性能提升会更明显。&lt;/p&gt;
&lt;h2 id=&quot;惠新宸&quot;&gt;&lt;a href=&quot;#惠新宸&quot; class=&quot;headerlink&quot; title=&quot;惠新宸&quot;&gt;&lt;/a&gt;惠新宸&lt;/h2&gt;&lt;p&gt;惠新宸 ，国内最有影响力的PHP技术专家， PHP开发组核心成员 , PECL开发者 , Zend公司外聘顾问, 曾供职于雅虎，百度，新浪。现任链家集团技术副总裁兼总架构师。PHP 7 的核心开发者，PHP5.4，5.5的主要开发者。也是Yaf (Yet another framework)，Yar(Yet another RPC framework) 以及Yac(Yet another Cache)、Taint等多个开源项目的作者，同时也是APC，Opcache ，Msgpack等项目的维护者。&lt;/p&gt;
&lt;h2 id=&quot;演讲实录&quot;&gt;&lt;a href=&quot;#演讲实录&quot; class=&quot;headerlink&quot; title=&quot;演讲实录&quot;&gt;&lt;/a&gt;演讲实录&lt;/h2&gt;&lt;p&gt;&lt;strong&gt;PHP Next: JIT&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://blog.p2hp.com/wp-content/uploads/2017/12/beepress-beepress-weixin-zhihu-jianshu-plugin-2-4-2-4899-1514626739-1.jpeg&quot; alt=&quot;鸟哥：PHP Next: JIT&quot;&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://blog.p2hp.com/wp-content/uploads/2017/12/beepress-beepress-weixin-zhihu-jianshu-plugin-2-4-2-4899-1514626740.jpeg&quot; alt=&quot;鸟哥：PHP Next: JIT&quot;&gt;&lt;/p&gt;
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>2017年PHP开发者大会总结 鸟哥JIT篇</title>
    <link href="http://yoursite.com/2018/01/04/THE-NEXT-GENERATION-OF-PHP/"/>
    <id>http://yoursite.com/2018/01/04/THE-NEXT-GENERATION-OF-PHP/</id>
    <published>2018-01-03T21:21:37.000Z</published>
    <updated>2018-01-03T21:32:54.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="2017年第三届PHP开发者大会总结-鸟哥JIT篇"><a href="#2017年第三届PHP开发者大会总结-鸟哥JIT篇" class="headerlink" title="2017年第三届PHP开发者大会总结 鸟哥JIT篇"></a>2017年第三届PHP开发者大会总结 鸟哥JIT篇</h1><p>鸟哥本次分享的主要内容是，在php7发布的这两年期间他们的主要工作，包括release的7.1和正在开发中的jit分支。说实话，由于本人水平有限，鸟哥分享的内容只能大概听懂意思，知道他们在做什么，但具体原理细节，鸟哥分享的我还真听不懂。这里就对鸟哥的分享内容做个总结。</p><h4 id="php7之后还有什么？JIT"><a href="#php7之后还有什么？JIT" class="headerlink" title="php7之后还有什么？JIT"></a>php7之后还有什么？JIT</h4><p>php7于15年正式发布，他的最大卖点是，无感知的100%性能提升，包含了运行速度与内存消耗。那么在此之后php该往哪里发展呢？目前已经在开发的一个大方向就是JIT</p><p><strong>JIT是什么？为什么是JIT？</strong><br>鸟哥并没有做过多的解释。我就谈一些我的肤浅认识，给phper们提供些参考。</p><p>首先JIT（just in time）并非是新技术，一大批语言如java早已实现。JIT的思想很简单，即在程序运行时动态对程序进行编译，生成平台相关的机器码，从而加快程序运行速度。</p><p>php文件的执行流程大致是首先引擎加载php文件，解释器逐条解释执行代码。引入JIT后，前面一样，重点是JIT编译器会根据Runtime信息对热点代码进行动态编译生成机器码，然后这部分代码以后就可以直接执行了，而不需要解释器逐条解释执行了，运行效率便得到了提升</p><p><code>看到这里不知道大家是否和我有一样的疑问，既然编译为机器码执行的效率那么高，为何不在项目正式部署前全部进行编译，何必在运行时编译？</code>要知道运行时编译也会增加程序的执行时间的。我在查阅了一些资料和一番思考后，有以下一些浅见</p><p>代码发布前先编译，是比JIT更早的通用办法，称为<code>AOT（ahead of time）</code>，c语言便是这种执行模式。关于这两种模式孰优孰劣，学术界一直争论不休，目前也没有定论。但JIT相比AOT有这样几个优点</p><ul><li><strong>发布速度快</strong>。不用每次都编译，发布速度自然快</li><li><strong>优化效率更好</strong>。因为JIT是基于Runtime信息，比AOT更“了解”代码，优化的效率更好。比如分析Runtime得知某个变量虽然声明是10个字节，但运行过程中一直是1个字节，那么就可以减小程序内存消耗；再比如某段代码始终未被执行，JIT则可以直接将其忽略</li><li><strong>粒度更精细</strong>。JIT可以只针对hotspot（热点）进行编译，热点可能是一个函数或者只是一个代码段</li><li><strong>对码农透明</strong>。JIT无须码农自己对程序根据不同平台进行编译发布，只需要写高级代码即可</li></ul><p>基于以上几个优点，再结合php一贯的简单易用原则，我想JIT确实是不错的选择。不过php也是支持AOT的，有兴趣的同学可以查一下。</p><a id="more"></a><p>但JIT技术也绝不是灵丹妙药，<code>即便是编译也是需要时间的，当代码编译的时间消耗大于运行收益时，程序反而会变慢！</code>会有这种情况吗？有的，比如某个项目中，热点并不明显，JIT编译的代码执行次数都很少，那么编译带来的收益是有可能小于编译本身的消耗的</p><p>以下是在标准测试中引入JIT技术后，php运行效率比7.2有100%的性能提升，不过在实际生产环境中效果不会有这么好</p><p><img src="http://ww1.sinaimg.cn/large/006DQdzWgy1fn44fznqc8j317u0f6wg1.jpg" alt=""></p><h4 id="php7-1做了什么？类型预测"><a href="#php7-1做了什么？类型预测" class="headerlink" title="php7.1做了什么？类型预测"></a>php7.1做了什么？类型预测</h4><p>php要想实现JIT，有一个难题必须解决，那就是变量的<code>类型预测</code>。试想如果在动态编译时还要进行大量的类型检查，性能将会大打折扣。php7中已经可以对变量类型进行控制，7.1则是更加完善了这个机制，可以说目前php已经是半强类型语言了。但由于php的弱类型历史，仍有大量代码运行前是无法得知变量类型的，所以在7.1中鸟哥进行了大量变量类型预测的工作，为后续JIT打基础</p><p><strong>变量预测</strong><br>比较简单的一种办法是数据流分析，即分析代码的上下文，推断出变量的可能类型，比如</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">function calc ($a1, $b2) &#123;        // $a1: [ANY], $b2: [ANY]</span><br><span class="line">    $T3 = $a1 * 2;                // $T3: [LONG, DOUBLE]</span><br><span class="line">    $a4 = $T3 % 1000;             // $a4: [LONG]</span><br><span class="line">    $T5 = $b2 * 3;                // $T5: [LONG, DOUBLE]</span><br><span class="line">    $b6 = $T5 % 1000;             // $b6: [LONG]</span><br><span class="line">    $T7 = $a4 + $b6;              // $T7: [LONG, DOUBLE]</span><br><span class="line">    return $T7;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>其实这还是很困难的，鸟哥列举了一些开发过程中遇到的困难。比如变量的变量，<code>$$var_name</code>，或者顶层代码（即写在函数和类之外的代码）等等。php的历史包袱还是很重的。解决这些问题的简单办法就是强类型，但这又会降低开发效率，<code>因为优化而影响phper的开发效率</code>这是鸟哥所不愿意的，他认为业务永远是优先的，优化只是支线</p><p>目前鸟哥的解决办法就是对JIT进行分级，通过配置实现不同程度的动态编译，从而降低类型预测的难度。另外就是针对具体的场景，进行垂直优化</p><h4 id="问答环节"><a href="#问答环节" class="headerlink" title="问答环节"></a>问答环节</h4><p>鸟哥的问答环节也非常精彩，原定一小时的分享最终超了一小时，下面我就凭着记忆对一些问题复现一下，<code>可能存在偏差，将来我可不负责</code></p><p><strong>php7.1那个诡异的函数返回类型限定是如何考虑的？</strong><br>鸟哥：没什么特别考虑，投票投出来的。首先说明一点，我投的是反对票。包括php的命名空间反斜杠我也是非常反对的，但可能由于我并没有对这方面太深的认识，没有理解其他开发者的意图。不过这些问题用习惯了也不是什么大的问题</p><p><strong>升级php7后，遇到了一个诡异的引用计数的问题。具体记不清了，大致是他们发现有个应该回收的变量在升级后没有回收</strong><br>鸟哥：我现在不能给你准确答复，有可能是个bug，这个我随后跟进一下。但我想说的是你刚才介绍了你们在调试过程中对引用数的反复推算，其实不必纠结这，引用数用于垃圾回收时只有0和非0两种区别，我们在增加引用计数时可能有时候不是加1，而是加2，所以不要太在意具体是多少，确定大于0就行</p><p><strong>一位学生提问者表示自己对高并发、分布式感兴趣，如何提升这方面的技能呢？</strong><br>鸟哥：这里你有一个误区。我们研究学习技术并不是为了学习而学习，而是为了解决实际的业务问题。你没有接触过这方面的业务，自然没有这方面的经验，等你真正有这个业务需求时，好多东西原理都很简单，使用方法也很成熟，自然就会了，这是个水到渠成的过程，不必刻意去追求那个“术”。另外，我多说一句是，其实当你真正处在这样的业务中时，你会发现这些事情很少需要你操心的，OP通过各种集群就已经把这些问题给屏蔽了。</p><p><strong>鸟哥你是怎样看待php的前景呢？现在黑php的这么多人</strong><br>鸟哥：php的前景不要问我，要问你和我，整个php生态。天峰贡献一个swoole，php就有了高性能网络请求功能，xx贡献个php-ml，php就有了大数据处理功能，我今天贡献一个jit，php就有了动态编译能力。php发展到今天就是大家你一个小贡献，他一个小贡献积累出来的，所以php的前景好不好，要看我们生态，也希望大家踊跃贡献。至于黑php，我现在都懒得反驳了，有句话说的好，“黑php之前，先数数他给你挣了多少钱”，我一直认为业务是技术存在的理由，能不能快速响应需求、实现业务才是最根本的。</p><p><strong>目前php没有连接池，非常不方便，不知道官方是否有支持计划？</strong><br>鸟哥：目前没有。不过这不正是一个给社区做贡献的机会吗？你们开发一个连接池，贡献到社区既方便了自己，也方便了大家。天峰昨天的分享PHP-X，不就是为了这样的事</p><p><strong>鸟哥你是怎样看待全栈工程师这个概念的？</strong><br>鸟哥：我并不认同这个概念，我认为这是个伪命题。全栈这个概念最早是前端工程师提出来的，认为从前端到后端这是“全栈”，但我理解的全栈应该是对一个领域从底层原理到上层应用，这不才更应该叫做栈？自称全栈工程师的大部分属于只对各个领域多少有些认识而已。优秀的工程师不必刻意去追求全栈，你只需要在你的领域里不断深入就行，深度达到了，自然就有了广度，<code>广度是深度的副产品</code>，推而广之，就是所谓的全栈工程师是当你在一个领域深入到一定阶段后的副产品，而不是刻意在各个领域学出来的</p><p><strong>php7对性能压榨已经比较彻底了，未来php是继续提高性能呢，还是增加新的特性？</strong><br>鸟哥：你想太多了，目前并未任何打算。JIT开发就非常困难了，这个是否能够成功还是未知数，下次大会如果JIT没有完成，我就没啥可分享的了。</p><p><strong>现在在北京很难安家，将来回到二三线城市，php很难找工作，不知道鸟哥有什么看法吗？</strong><br>鸟哥：不必过于担心，不光是程序猿，其实还有好多公司也很难承受一线城市的成本，也在不断的往二三城市分流，所以找工作问题还是不大的。另外至于你担心php难找工作，那你可以换java、换go啊，一个程序猿不应该给自己打上标签，“xx程序猿”，你作为一个工程师，至少要精通3种以上的语言，而且要有良好的学习能力</p><p><strong>鸟哥你是如何放松你的部下呢？会请他们去大保健吗？</strong><br>鸟哥：这个我没太多经验，不过就我自己来说，有时候加班多了还是比较累的，我有段时间脖子特别疼，一周得去至少三次按摩院按摩才能缓解，当然我说的是盲人按摩。后来我真的研究了颈椎康复指南，不是开玩笑，我是真研究了。人的脑袋大概12斤重，你想你整天顶个西瓜，要是颈椎肌肉不行的话，能不难受吗？所以我后来经常去健身房，锻炼颈椎，后来才慢慢好了</p>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;2017年第三届PHP开发者大会总结-鸟哥JIT篇&quot;&gt;&lt;a href=&quot;#2017年第三届PHP开发者大会总结-鸟哥JIT篇&quot; class=&quot;headerlink&quot; title=&quot;2017年第三届PHP开发者大会总结 鸟哥JIT篇&quot;&gt;&lt;/a&gt;2017年第三届PHP开发者大会总结 鸟哥JIT篇&lt;/h1&gt;&lt;p&gt;鸟哥本次分享的主要内容是，在php7发布的这两年期间他们的主要工作，包括release的7.1和正在开发中的jit分支。说实话，由于本人水平有限，鸟哥分享的内容只能大概听懂意思，知道他们在做什么，但具体原理细节，鸟哥分享的我还真听不懂。这里就对鸟哥的分享内容做个总结。&lt;/p&gt;
&lt;h4 id=&quot;php7之后还有什么？JIT&quot;&gt;&lt;a href=&quot;#php7之后还有什么？JIT&quot; class=&quot;headerlink&quot; title=&quot;php7之后还有什么？JIT&quot;&gt;&lt;/a&gt;php7之后还有什么？JIT&lt;/h4&gt;&lt;p&gt;php7于15年正式发布，他的最大卖点是，无感知的100%性能提升，包含了运行速度与内存消耗。那么在此之后php该往哪里发展呢？目前已经在开发的一个大方向就是JIT&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;JIT是什么？为什么是JIT？&lt;/strong&gt;&lt;br&gt;鸟哥并没有做过多的解释。我就谈一些我的肤浅认识，给phper们提供些参考。&lt;/p&gt;
&lt;p&gt;首先JIT（just in time）并非是新技术，一大批语言如java早已实现。JIT的思想很简单，即在程序运行时动态对程序进行编译，生成平台相关的机器码，从而加快程序运行速度。&lt;/p&gt;
&lt;p&gt;php文件的执行流程大致是首先引擎加载php文件，解释器逐条解释执行代码。引入JIT后，前面一样，重点是JIT编译器会根据Runtime信息对热点代码进行动态编译生成机器码，然后这部分代码以后就可以直接执行了，而不需要解释器逐条解释执行了，运行效率便得到了提升&lt;/p&gt;
&lt;p&gt;&lt;code&gt;看到这里不知道大家是否和我有一样的疑问，既然编译为机器码执行的效率那么高，为何不在项目正式部署前全部进行编译，何必在运行时编译？&lt;/code&gt;要知道运行时编译也会增加程序的执行时间的。我在查阅了一些资料和一番思考后，有以下一些浅见&lt;/p&gt;
&lt;p&gt;代码发布前先编译，是比JIT更早的通用办法，称为&lt;code&gt;AOT（ahead of time）&lt;/code&gt;，c语言便是这种执行模式。关于这两种模式孰优孰劣，学术界一直争论不休，目前也没有定论。但JIT相比AOT有这样几个优点&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;发布速度快&lt;/strong&gt;。不用每次都编译，发布速度自然快&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;优化效率更好&lt;/strong&gt;。因为JIT是基于Runtime信息，比AOT更“了解”代码，优化的效率更好。比如分析Runtime得知某个变量虽然声明是10个字节，但运行过程中一直是1个字节，那么就可以减小程序内存消耗；再比如某段代码始终未被执行，JIT则可以直接将其忽略&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;粒度更精细&lt;/strong&gt;。JIT可以只针对hotspot（热点）进行编译，热点可能是一个函数或者只是一个代码段&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;对码农透明&lt;/strong&gt;。JIT无须码农自己对程序根据不同平台进行编译发布，只需要写高级代码即可&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;基于以上几个优点，再结合php一贯的简单易用原则，我想JIT确实是不错的选择。不过php也是支持AOT的，有兴趣的同学可以查一下。&lt;/p&gt;
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>如何在PDO查询中返回强类型</title>
    <link href="http://yoursite.com/2017/12/30/how-to-use-strong-type-in-pdo/"/>
    <id>http://yoursite.com/2017/12/30/how-to-use-strong-type-in-pdo/</id>
    <published>2017-12-30T05:11:36.000Z</published>
    <updated>2017-12-30T06:21:29.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="如何在PDO查询中返回强类型"><a href="#如何在PDO查询中返回强类型" class="headerlink" title="如何在PDO查询中返回强类型"></a>如何在PDO查询中返回强类型</h1><blockquote><p> 有些驱动不支持或有限度地支持本地预处理。使用此设置强制PDO总是模拟预处理语句（如果为 TRUE ），或试着使用本地预处理语句（如果为 FALSE）。如果驱动不能成功预处理当前查询，它将总是回到模拟预处理语句上。 需要 bool 类型。</p></blockquote><p>PDO::ATTR_EMULATE_PREPARES 启用或禁用预处理语句的模拟。</p><p>这是之前我说的默认总是模拟prepare,因为低版本MYSQL驱动不支持prepare.<br>数据类型问题,在旧版本的MySQL中还真是不能解决的。它直接返回字符串给外部系统。稍微新一点的MySQL和客户端驱动可以直接内部的本地类型而不再进行内部转换为字符串了。有了这个基础，就有解决的可能了。</p><h4 id="Test-code"><a href="#Test-code" class="headerlink" title="Test-code"></a>Test-code</h4><p>此处用query测试证明,prepare_excute二连也是一样的</p><figure class="highlight php"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$db = <span class="keyword">new</span> \PDO(<span class="string">'mysql:dbname='</span>.$options[<span class="string">'database'</span>].<span class="string">';host='</span>.$options[<span class="string">'host'</span>], $options[<span class="string">'user'</span>], $options[<span class="string">'password'</span>]);</span><br><span class="line">$db-&gt;setAttribute(\PDO::ATTR_EMULATE_PREPARES, <span class="keyword">false</span>);<span class="comment">//关闭预处理语句模拟</span></span><br><span class="line">$r = ($db-&gt;query(<span class="string">'SELECT * FROM test WHERE `id`=1 LIMIT 1'</span>, \PDO::FETCH_ASSOC))-&gt;fetch();</span><br><span class="line">var_dump($r);</span><br></pre></td></tr></table></figure><h4 id="result"><a href="#result" class="headerlink" title="$result"></a>$result</h4><figure class="highlight php"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">array</span>(<span class="number">2</span>) &#123;</span><br><span class="line">  [<span class="number">0</span>]=&gt;</span><br><span class="line">  int(<span class="number">1</span>)</span><br><span class="line">  [<span class="number">1</span>]=&gt;</span><br><span class="line">  string(<span class="number">64</span>) <span class="string">"1dfd47ed5fb0183d05157f21cab0fd8c151379f407a173190445bbd82aa5aeaa"</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>此外,PDO为参数绑定也提供了强类型的设定,默认传给Mysql的是string,常用的类型如下:</p><figure class="highlight php"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">$data_types = [</span><br><span class="line">  <span class="string">'NULL'</span>    =&gt; PDO::PARAM_NULL,</span><br><span class="line">  <span class="string">'boolean'</span> =&gt; PDO::PARAM_BOOL,</span><br><span class="line">  <span class="string">'integer'</span> =&gt; PDO::PARAM_INT,</span><br><span class="line">  <span class="string">'string'</span>  =&gt; PDO::PARAM_STR,</span><br><span class="line">]</span><br><span class="line"><span class="keyword">$this</span>-&gt;sm-&gt;bindParam(<span class="string">':id'</span>, $id, $data_types[getType($id)]);</span><br></pre></td></tr></table></figure><blockquote><p>data<em>type: 使用[*PDO :: PARAM</em> ** 常量](<a href="http://php.net/manual/en/pdo.constants.php)来设定参数的显式数据类型。要从存储过程返回INOUT参数，请使用按位或运算符来设置`data_type`参数的PDO" target="_blank" rel="noopener">http://php.net/manual/en/pdo.constants.php)来设定参数的显式数据类型。要从存储过程返回INOUT参数，请使用按位或运算符来设置`data_type`参数的PDO</a> :: PARAM_INPUT_OUTPUT位。</p></blockquote>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;如何在PDO查询中返回强类型&quot;&gt;&lt;a href=&quot;#如何在PDO查询中返回强类型&quot; class=&quot;headerlink&quot; title=&quot;如何在PDO查询中返回强类型&quot;&gt;&lt;/a&gt;如何在PDO查询中返回强类型&lt;/h1&gt;&lt;blockquote&gt;
&lt;p&gt; 有些驱动不支持或
      
    
    </summary>
    
      <category term="PHP" scheme="http://yoursite.com/categories/PHP/"/>
    
      <category term="Mysql" scheme="http://yoursite.com/categories/PHP/Mysql/"/>
    
    
      <category term="PDO" scheme="http://yoursite.com/tags/PDO/"/>
    
      <category term="Mysql" scheme="http://yoursite.com/tags/Mysql/"/>
    
      <category term="参数化" scheme="http://yoursite.com/tags/%E5%8F%82%E6%95%B0%E5%8C%96/"/>
    
  </entry>
  
  <entry>
    <title>让 CPU 告诉你硬盘和网络到底有多慢</title>
    <link href="http://yoursite.com/2017/12/28/how-slow-is-disk-and-network/"/>
    <id>http://yoursite.com/2017/12/28/how-slow-is-disk-and-network/</id>
    <published>2017-12-28T08:18:03.000Z</published>
    <updated>2017-12-30T05:08:35.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="让-CPU-告诉你硬盘和网络到底有多慢"><a href="#让-CPU-告诉你硬盘和网络到底有多慢" class="headerlink" title="让 CPU 告诉你硬盘和网络到底有多慢"></a>让 CPU 告诉你硬盘和网络到底有多慢</h1><blockquote><p>本文转载自 <a href="http://cizixs.com/2017/01/03/how-slow-is-disk-and-network" target="_blank" rel="noopener">cizixs</a></p></blockquote><h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><p>经常听到有人说磁盘很慢、网络很卡，这都是站在人类的感知维度去表述的，比如拷贝一个文件到硬盘需要几分钟到几十分钟，够我去吃个饭啦；而从网络下载一部电影，有时候需要几个小时，我都可以睡一觉了。</p><p>最为我们熟知的关于计算机不同组件速度差异的图表，是下面这种金字塔形式：越往上速度越快，容量越小，而价格越高。这张图只是给了我们一个直观地感觉，并没有对各个速度和性能做出量化的说明和解释。而实际上，不同层级之间的差异要比这张图大的多。这篇文章就让你站在 CPU 的角度看这个世界，说说到底它们有多慢。</p><p><img src="http://s7.computerhistory.org/is/image/CHM/500004956?$re-zoomed$" alt="img"></p><p>希望你看到看完这篇文章能明白两件事情：磁盘和网络真的很慢，性能优化是个复杂的系统性的活。</p><a id="more"></a><p>注：所有的数据都是来自<a href="https://gist.github.com/hellerbarde/2843375" target="_blank" rel="noopener">这个地址</a>。所有的数据会因为机器配置不同，或者硬件的更新而有出入，但是不影响我们直觉的感受。如果对这些数据比较感兴趣，<a href="https://people.eecs.berkeley.edu/~rcs/research/interactive_latency.html" target="_blank" rel="noopener">这个网址</a>给出了不同年份一些指标的数值。</p><h2 id="数据"><a href="#数据" class="headerlink" title="数据"></a>数据</h2><ul><li>先来看看 CPU 的速度，就拿我的电脑来说，主频是 2.6G，也就是说每秒可以执行 <code>2.6*10^9</code>个指令，每个指令只需要 <code>0.38ns</code>（现在很多个人计算机的主频要比这个高，配置比较高的能达到 3.0G+）。我们把这个时间当做基本单位 <code>1s</code>，因为 <code>1s</code> 大概是人类能感知的最小时间单位。</li></ul><p><img src="http://photocdn.sohu.com/20141022/Img405364158.jpg" alt="img"></p><ul><li>一级缓存读取时间为 <code>0.5ns</code>，换算成人类时间大约是 <code>1.3s</code>，大约一次或者两次心跳的时间。这里能看出缓存的重要性，因为它的速度可以赶上 CPU，程序本身的 locality 特性加上指令层级上的优化，cache 访问的命中率很高，这最终能极大提高效率。</li><li>分支预测错误需要耗时 <code>5ns</code>，换算成人类时间大约是 <code>13s</code>，这个就有点久了，所以你会看到很多文章分析如何优化代码来降低分支预测的几率，比如<a href="http://stackoverflow.com/questions/11227809/why-is-it-faster-to-process-a-sorted-array-than-an-unsorted-array" target="_blank" rel="noopener">这个得分非常高的 stackoverflow 问题</a>。</li><li>二级缓存时间就比较久了，大约在 <code>7ns</code>，换算成人类时间大约是 <code>18.2s</code>，可以看到的是如果一级缓存没有命中，然后去二级缓存读取数据，时间差了一个数量级。</li></ul><p><strong>小知识：</strong>为什么需要多层的 CPU 缓存呢？<a href="https://fgiesen.wordpress.com/2016/08/07/why-do-cpus-have-multiple-cache-levels/" target="_blank" rel="noopener">这篇文章通过一个通俗易懂的例子给出了讲解</a>。</p><ul><li>我们继续，互斥锁的加锁和解锁时间需要 <code>25ns</code>，换算成人类时间大约是 <code>65s</code>，首次达到了一分钟。并发编程中，我们经常听说锁是一个很耗时的东西，因为在微波炉里加热一个东西需要一分钟的话，你要在那傻傻地等蛮久了。</li><li>然后就到了内存，每次内存寻址需要 <code>100ns</code>，换算成人类时间是 <code>260s</code>，也就是<code>4分多钟</code>，如果读一些不需要太多思考的文章，这么久能读完2-3千字（这个快阅读的时代，很少人在手机上能静心多这么字了）。看起来还不算坏，不多要从内存中读取一段数据需要的时间会更多。到了内存之后，时间就变了一个量级，CPU 和内存之间的速度瓶颈被称为<a href="https://en.wikipedia.org/wiki/Von_Neumann_architecture#Von_Neumann_bottleneck" target="_blank" rel="noopener">冯诺依曼瓶颈</a>。</li><li>一次 CPU 上下文切换（系统调用）需要大约 <code>1500ns</code>，也就是 <code>1.5us</code>（这个数字参考了<a href="http://blog.tsunanet.net/2010/11/how-long-does-it-take-to-make-context.html" target="_blank" rel="noopener">这篇文章</a>，采用的是单核 CPU 线程平均时间），换算成人类时间大约是 <code>65分钟</code>，嗯，也就是一个小时。我们也知道上下文切换是很耗时的行为，毕竟每次浪费一个小时，也很让人有罪恶感的。上下文切换更恐怖的事情在于，<strong>这段时间里 CPU 没有做任何有用的计算</strong>，只是切换了两个不同进程的寄存器和内存状态；而且这个过程<strong>还破坏了缓存，</strong>让后续的计算更加耗时。</li><li>在 1Gbps 的网络上传输 2K 的数据需要 <code>20us</code>，换算成人类时间是 <code>14.4小时</code>，这么久都能把《星球大战》六部曲看完了（甚至还加上吃饭撒尿的时间）！可以看到网络上非常少数据传输对于 CPU 来说，已经很漫长。而且这里的时间还是理论最大值，实际过程还要更慢一些。</li><li>SSD 随机读取耗时为 <code>150us</code>，换算成人类时间大约是 <code>4.5天</code>。换句话说，SSD 读点数据，CPU 都能休假，报团参加周边游了。虽然我们知道 SSD 要比机械硬盘快很多，但是这个速度对于 CPU 来说也是像乌龟一样。<code>I/O 设备</code> 从硬盘开始速度开始变得漫长，这个时候我们就想起内存的好处了。尽量减少 IO 设备的读写，把最常用的数据放到内存中作为缓存是所有程序的通识。像 <code>memcached</code> 和 <code>redis</code> 这样的高速缓存系统近几年的异军突起，就是解决了这里的问题。</li><li>从内存中读取 <code>1MB</code> 的连续数据，耗时大约为 <code>250us</code>，换算成人类时间是 <code>7.5天</code>，这次假期升级到国庆七天国外游了。</li><li>同一个数据中心网络上跑一个来回需要 <code>0.5ms</code>，换算成人类时间大约是 <code>15天</code>，也就是半个月的时间。如果你的程序有段代码需要和数据中心的其他服务器交互，在这段时间里 CPU 都已经狂做了半个月的运算。减少不同服务组件的网络请求，是性能优化的一大课题。</li><li>从 SSD 读取 1MB 的顺序数据，大约需要 <code>1ms</code>，换算成人类时间是 <code>1个月</code>。也就是说 SSD 读一个普通的文件，如果要等你做完，CPU 一个月时间就荒废了。尽管如此，<strong>SSD</strong> 已经很快啦，不信你看下面机械磁盘的表现。</li><li>磁盘寻址时间为 <code>10ms</code>，换算成人类时间是 <code>10个月</code>，刚好够人类创造一个新的生命了。如果 CPU 需要让磁盘泡杯咖啡，在它眼里，磁盘去生了个孩子，回来告诉它你让我泡的咖啡好了。机械硬盘使用 <code>RPM(Revolutions Per Minute/每分钟转速)</code> 来评估磁盘的性能：RPM 越大，平均寻址时间更短，磁盘性能越好。寻址只是把磁头移动到正确的磁道上，然后才能读取指定扇区的内容。换句话说，寻址虽然很浪费时间，但其实它并没有办任何的正事（读取磁盘内容）。</li><li>从磁盘读取 1MB 连续数据需要 <code>20ms</code>，换算成人类时间是 <code>20个月</code>。<strong>IO 设备是计算机系统的瓶颈</strong>，希望读到这里你能更深切地理解这句话！如果还不理解，不妨想想你在网上买的东西，快递送了将近两年，你的心情是怎么样的。</li><li>而从世界上不同城市网络上走一个来回，平均需要 <code>150ms</code>（参考<a href="https://wondernetwork.com/pings/" target="_blank" rel="noopener">世界各地 ping 报文的时间</a>），换算成人类时间是 <code>12.5年</code>。不难理解，所有的程序和架构都会尽量避免不同城市甚至是跨国家的网络访问，<a href="https://en.wikipedia.org/wiki/Content_delivery_network" target="_blank" rel="noopener">CDN</a> 就是这个问题的一个解决方案：让用户和最接近自己的服务器交互，从而减少网络上报文的传输时间。</li><li>虚拟机重启一次大约要 <code>4s</code> 时间，换算成人类的时间是 <code>3百多年</code>。对于此，我想到了乔布斯要死命<a href="http://stevejobsdailyquote.com/2014/03/26/boot-time/" target="_blank" rel="noopener">优化 Mac 系统开机启动时间</a>的故事。如果机器能少重启而且每次启动能快一点，不仅能救人命，也能救 CPU 的命。</li><li>物理服务器重启一次需要 <code>5min</code>，换算成人类时间是 <code>2万5千年</code>，快赶上人类的文明史了。5 分钟人类都要等一会了，更别提 CPU 了，所以没事不要乱重启服务器啊，分分钟终结一个文明的节奏。</li></ul><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ul><li><a href="https://www.akkadia.org/drepper/cpumemory.pdf" target="_blank" rel="noopener">What Every Programmer Should Know About Memory</a></li><li><a href="http://duartes.org/gustavo/blog/post/getting-physical-with-memory/" target="_blank" rel="noopener">Getting Physical With Memory</a></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;让-CPU-告诉你硬盘和网络到底有多慢&quot;&gt;&lt;a href=&quot;#让-CPU-告诉你硬盘和网络到底有多慢&quot; class=&quot;headerlink&quot; title=&quot;让 CPU 告诉你硬盘和网络到底有多慢&quot;&gt;&lt;/a&gt;让 CPU 告诉你硬盘和网络到底有多慢&lt;/h1&gt;&lt;blockquote&gt;
&lt;p&gt;本文转载自 &lt;a href=&quot;http://cizixs.com/2017/01/03/how-slow-is-disk-and-network&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;cizixs&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&quot;简介&quot;&gt;&lt;a href=&quot;#简介&quot; class=&quot;headerlink&quot; title=&quot;简介&quot;&gt;&lt;/a&gt;简介&lt;/h2&gt;&lt;p&gt;经常听到有人说磁盘很慢、网络很卡，这都是站在人类的感知维度去表述的，比如拷贝一个文件到硬盘需要几分钟到几十分钟，够我去吃个饭啦；而从网络下载一部电影，有时候需要几个小时，我都可以睡一觉了。&lt;/p&gt;
&lt;p&gt;最为我们熟知的关于计算机不同组件速度差异的图表，是下面这种金字塔形式：越往上速度越快，容量越小，而价格越高。这张图只是给了我们一个直观地感觉，并没有对各个速度和性能做出量化的说明和解释。而实际上，不同层级之间的差异要比这张图大的多。这篇文章就让你站在 CPU 的角度看这个世界，说说到底它们有多慢。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://s7.computerhistory.org/is/image/CHM/500004956?$re-zoomed$&quot; alt=&quot;img&quot;&gt;&lt;/p&gt;
&lt;p&gt;希望你看到看完这篇文章能明白两件事情：磁盘和网络真的很慢，性能优化是个复杂的系统性的活。&lt;/p&gt;
    
    </summary>
    
      <category term="编程原理" scheme="http://yoursite.com/categories/%E7%BC%96%E7%A8%8B%E5%8E%9F%E7%90%86/"/>
    
    
      <category term="cpu" scheme="http://yoursite.com/tags/cpu/"/>
    
      <category term="memory" scheme="http://yoursite.com/tags/memory/"/>
    
      <category term="disk" scheme="http://yoursite.com/tags/disk/"/>
    
      <category term="network" scheme="http://yoursite.com/tags/network/"/>
    
  </entry>
  
  <entry>
    <title>woo</title>
    <link href="http://yoursite.com/2017/12/28/test/"/>
    <id>http://yoursite.com/2017/12/28/test/</id>
    <published>2017-12-28T02:40:00.000Z</published>
    <updated>2017-12-28T02:51:09.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="｡･∀･-ﾉﾞ"><a href="#｡･∀･-ﾉﾞ" class="headerlink" title="(｡･∀･)ﾉﾞ"></a>(｡･∀･)ﾉﾞ</h1><h2 id="👁SEE-IS-THE-🐳SEA-OF-CC😎"><a href="#👁SEE-IS-THE-🐳SEA-OF-CC😎" class="headerlink" title="👁SEE IS THE 🐳SEA OF CC😎"></a>👁SEE IS THE 🐳SEA OF CC😎</h2><p>My name is cc,</p><p>so I’m <strong>Twosee</strong>.</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;｡･∀･-ﾉﾞ&quot;&gt;&lt;a href=&quot;#｡･∀･-ﾉﾞ&quot; class=&quot;headerlink&quot; title=&quot;(｡･∀･)ﾉﾞ&quot;&gt;&lt;/a&gt;(｡･∀･)ﾉﾞ&lt;/h1&gt;&lt;h2 id=&quot;👁SEE-IS-THE-🐳SEA-OF-CC😎&quot;&gt;&lt;a href=&quot;#👁SEE
      
    
    </summary>
    
    
  </entry>
  
</feed>
